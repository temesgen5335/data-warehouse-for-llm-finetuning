{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "75f4a8391479a6ab"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:26:22.199518Z",
     "start_time": "2024-05-21T04:26:22.196452Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Tokenize text into words and remove English stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove english words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d923ac01294f6952"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 1 - Using NLTK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a603b46a8e12dad5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0a37ce756e81764"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "text = \"Huyu jamaa anaongea this is the work of the guy in the pub Kiswahili vizuri sana, lakini pia anajua Kiingereza.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:35:54.766794Z",
     "start_time": "2024-05-21T04:35:54.764102Z"
    }
   },
   "id": "c4bcaf90b198a0da",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huyu jamaa anaongea work guy pub kiswahili vizuri sana , lakini pia anajua kiingereza .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hilla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hilla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def extract_swahili_words_nltk(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    swahili_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return \" \".join(swahili_words)\n",
    "\n",
    "filtered_text = extract_swahili_words_nltk(text)\n",
    "print(filtered_text)  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:26:45.351673Z",
     "start_time": "2024-05-21T04:26:45.343318Z"
    }
   },
   "id": "660c497a0db7e7f0",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 2 - Using langdetect"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca7a9bb5997d3730"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiswahili lakini Kiingereza.\n"
     ]
    }
   ],
   "source": [
    "import langdetect  # pip install langdetect\n",
    "\n",
    "def extract_swahili_words_langdetect(text):\n",
    "    words = text.split()\n",
    "    swahili_words = [word for word in words if langdetect.detect(word) == 'sw']\n",
    "    return \" \".join(swahili_words)\n",
    "\n",
    "text = \"Huyu jamaa anaongea Kiswahili vizuri sana, lakini pia anajua Kiingereza.\"\n",
    "filtered_text = extract_swahili_words_langdetect(text)\n",
    "print(filtered_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:30:08.342603Z",
     "start_time": "2024-05-21T04:30:07.759135Z"
    }
   },
   "id": "36e49dd0e7dc21bd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 3 - Using langid"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4d1ba53f602d74"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# pip install langid\n",
    "import langid\n",
    "\n",
    "def extract_swahili_words_langid(text):\n",
    "    words = text.split()\n",
    "    swahili_words = [word for word in words if langid.classify(word)[0] == 'sw']\n",
    "    return \" \".join(swahili_words)\n",
    "\n",
    "text = \"Huyu jamaa anaongea Kiswahili vizuri sana, lakini pia anajua Kiingereza.\"\n",
    "filtered_text = extract_swahili_words_langid(text)\n",
    "print(filtered_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:31:51.184118Z",
     "start_time": "2024-05-21T04:31:49.248384Z"
    }
   },
   "id": "7505b2494baa0ba2",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 4 - Using fasttext"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbac11dd213ec76"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lid.176.bin cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(swahili_words)\n\u001B[1;32m      9\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHuyu jamaa anaongea Kiswahili vizuri sana, lakini pia anajua Kiingereza.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 10\u001B[0m filtered_text \u001B[38;5;241m=\u001B[39m \u001B[43mextract_swahili_words_fasttext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(filtered_text)\n",
      "Cell \u001B[0;32mIn[9], line 6\u001B[0m, in \u001B[0;36mextract_swahili_words_fasttext\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_swahili_words_fasttext\u001B[39m(text):\n\u001B[1;32m      5\u001B[0m     words \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39msplit()\n\u001B[0;32m----> 6\u001B[0m     swahili_words \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m words \u001B[38;5;28;01mif\u001B[39;00m fasttext\u001B[38;5;241m.\u001B[39mload_model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlid.176.bin\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mpredict(word)[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__label__sw\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(swahili_words)\n",
      "Cell \u001B[0;32mIn[9], line 6\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_swahili_words_fasttext\u001B[39m(text):\n\u001B[1;32m      5\u001B[0m     words \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39msplit()\n\u001B[0;32m----> 6\u001B[0m     swahili_words \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m words \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mfasttext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlid.176.bin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(word)[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__label__sw\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(swahili_words)\n",
      "File \u001B[0;32m~/code/10Academy-training/week4/fastApiProject_test/.venv/lib/python3.10/site-packages/fasttext/FastText.py:441\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001B[39;00m\n\u001B[1;32m    440\u001B[0m eprint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_FastText\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/10Academy-training/week4/fastApiProject_test/.venv/lib/python3.10/site-packages/fasttext/FastText.py:98\u001B[0m, in \u001B[0;36m_FastText.__init__\u001B[0;34m(self, model_path, args)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m fasttext\u001B[38;5;241m.\u001B[39mfasttext()\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: lid.176.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "# pip install fasttext\n",
    "import fasttext\n",
    "\n",
    "def extract_swahili_words_fasttext(text):\n",
    "    words = text.split()\n",
    "    swahili_words = [word for word in words if fasttext.load_model('lid.176.bin').predict(word)[0][0] == '__label__sw']\n",
    "    return \" \".join(swahili_words)\n",
    "\n",
    "text = \"Huyu jamaa anaongea Kiswahili vizuri sana, lakini pia anajua Kiingereza.\"\n",
    "filtered_text = extract_swahili_words_fasttext(text)\n",
    "print(filtered_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:33:42.031845Z",
     "start_time": "2024-05-21T04:33:41.947975Z"
    }
   },
   "id": "600628ad7dbe67b8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: Install the langdetect library\n",
    "# You can do this in your terminal using the command: pip install langdetect\n",
    "\n",
    "# Step 2: Import the detect function\n",
    "from langdetect import detect\n",
    "\n",
    "# Step 3: Create a function to detect if a string is in English\n",
    "def is_english(s):\n",
    "    try:\n",
    "        return detect(s) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Step 4: Use a list comprehension to filter your data\n",
    "english_data = [s for s in text.split() if is_english(s)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:36:05.050501Z",
     "start_time": "2024-05-21T04:36:04.905355Z"
    }
   },
   "id": "bf9917f80a7e29bf",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['this', 'the', 'of', 'the', 'the']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:36:09.136213Z",
     "start_time": "2024-05-21T04:36:09.128795Z"
    }
   },
   "id": "d584262964c674d6",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Habari za leo?', 'Ninaongea na naenda work to stay in Kiswahili na Kiingereza.']\n",
      "['This is an English sentence.']\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "\n",
    "def filter_swahili_text(text_list, confidence_threshold=0.8):\n",
    "    swahili_texts = []\n",
    "    english_rich_texts = []\n",
    "    for text in text_list:\n",
    "        try:\n",
    "            lang = langdetect.detect(text)\n",
    "            if lang == 'sw' and langdetect.detect_langs(text)[0].prob > confidence_threshold:\n",
    "                swahili_texts.append(text)\n",
    "            else:\n",
    "                english_rich_texts.append(text)\n",
    "        except langdetect.LangDetectException:\n",
    "            pass # Skip texts that can't be detected \n",
    "    return swahili_texts, english_rich_texts\n",
    "\n",
    "# Example usage\n",
    "text_list = [\"Habari za leo?\", \"This is an English sentence.\", \"Ninaongea na naenda work to stay in Kiswahili na Kiingereza.\"]\n",
    "swahili_texts, english_rich_texts = filter_swahili_text(text_list)\n",
    "print(swahili_texts)  \n",
    "print(english_rich_texts)  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T04:38:12.619091Z",
     "start_time": "2024-05-21T04:38:12.566829Z"
    }
   },
   "id": "8fe11b5ab5e43208",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get all the english words from the web2 dictionary and remove them from the swahili text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "627d3a13321edc32"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huyu jamaa anaongea vizuri sana, lakini anajua Kiingereza.\n"
     ]
    }
   ],
   "source": [
    "from english_words import get_english_words_set\n",
    "\n",
    "def remove_english_words(swahili_text):\n",
    "    web2lowerset = get_english_words_set(['web2'], lower=True)\n",
    "\n",
    "    swahili_words = swahili_text.split()\n",
    "    filtered_words = [word for word in swahili_words if word.lower() not in web2lowerset]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Example usage\n",
    "swahili_text_with_english = \"Huyu jamaa anaongea this Kiswahili and him vizuri sana, why lakini pia anajua Kiingereza.\"\n",
    "filtered_swahili_text = remove_english_words(swahili_text_with_english)\n",
    "print(filtered_swahili_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T05:03:09.210181Z",
     "start_time": "2024-05-21T05:03:09.118675Z"
    }
   },
   "id": "9b66ceabed37f122",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
