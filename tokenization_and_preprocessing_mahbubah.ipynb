{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>article</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>የኦሊምፒክ ማጣሪያ ተሳታፊዎች የሚለዩበት ቻምፒዮና እየተካሄደ ይገኛል</td>\n",
       "      <td>ስፖርት</td>\n",
       "      <td>January 14, 2021</td>\n",
       "      <td>2</td>\n",
       "      <td>ብርሃን ፈይሳየኢትዮጵያ ቦክስ ፌዴሬሽን በየዓመቱ የሚያዘጋጀው የክለቦች ቻ...</td>\n",
       "      <td>https://www.press.et/Ama/?p=39481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>አዲስ ዘመን ድሮ</td>\n",
       "      <td>መዝናኛ</td>\n",
       "      <td>December 28, 2020</td>\n",
       "      <td>4</td>\n",
       "      <td>የአዲስ ዘመን ጋዜጣ ቀደምት ዘገባዎች በእጅጉ ተነባቢ ዛሬም ላገኛቸው በ...</td>\n",
       "      <td>https://www.press.et/Ama/?p=38334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>የአረንጓዴ ጎርፍ በጎ አድራጎት አምባሳደሮች ተሰየሙ</td>\n",
       "      <td>ስፖርት</td>\n",
       "      <td>January 6, 2021</td>\n",
       "      <td>6</td>\n",
       "      <td>ቦጋለ አበበየአዲስ አበባ ከተማ አስተዳደር ስፖርት ኮሚሽን ከኢትዮጵያ አረ...</td>\n",
       "      <td>https://www.press.et/Ama/?p=39010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>የሊጉ በቢዝነስ ሞዴል መመራት አበረታች ጅምር መሆኑ ተገለጸ</td>\n",
       "      <td>ስፖርት</td>\n",
       "      <td>January 6, 2021</td>\n",
       "      <td>5</td>\n",
       "      <td>ብርሃን ፈይሳአዲስ አበባ፡- የኢትዮጵያ ፕሪምየር ሊግ በሼር ካምፓኒ እንዲ...</td>\n",
       "      <td>https://www.press.et/Ama/?p=39011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>የኦሊምፒክ ሥራ አስፈፃሚው እስከ ቶኪዮ ኦሊምፒክ ማግስት ይቀጥላል</td>\n",
       "      <td>ስፖርት</td>\n",
       "      <td>January 6, 2021</td>\n",
       "      <td>12</td>\n",
       "      <td>ቦጋለ አበበ የኢትዮጵያ ኦሊምፒክ ኮሚቴ አርባ አምስተኛ መደበኛ ጠቅላላ ጉ...</td>\n",
       "      <td>https://www.press.et/Ama/?p=39012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      headline category               date  \\\n",
       "0  የኦሊምፒክ ማጣሪያ ተሳታፊዎች የሚለዩበት ቻምፒዮና እየተካሄደ ይገኛል     ስፖርት   January 14, 2021   \n",
       "1                                   አዲስ ዘመን ድሮ     መዝናኛ  December 28, 2020   \n",
       "2             የአረንጓዴ ጎርፍ በጎ አድራጎት አምባሳደሮች ተሰየሙ     ስፖርት    January 6, 2021   \n",
       "3        የሊጉ በቢዝነስ ሞዴል መመራት አበረታች ጅምር መሆኑ ተገለጸ     ስፖርት    January 6, 2021   \n",
       "4    የኦሊምፒክ ሥራ አስፈፃሚው እስከ ቶኪዮ ኦሊምፒክ ማግስት ይቀጥላል     ስፖርት    January 6, 2021   \n",
       "\n",
       "  views                                            article  \\\n",
       "0     2  ብርሃን ፈይሳየኢትዮጵያ ቦክስ ፌዴሬሽን በየዓመቱ የሚያዘጋጀው የክለቦች ቻ...   \n",
       "1     4   የአዲስ ዘመን ጋዜጣ ቀደምት ዘገባዎች በእጅጉ ተነባቢ ዛሬም ላገኛቸው በ...   \n",
       "2     6  ቦጋለ አበበየአዲስ አበባ ከተማ አስተዳደር ስፖርት ኮሚሽን ከኢትዮጵያ አረ...   \n",
       "3     5  ብርሃን ፈይሳአዲስ አበባ፡- የኢትዮጵያ ፕሪምየር ሊግ በሼር ካምፓኒ እንዲ...   \n",
       "4    12  ቦጋለ አበበ የኢትዮጵያ ኦሊምፒክ ኮሚቴ አርባ አምስተኛ መደበኛ ጠቅላላ ጉ...   \n",
       "\n",
       "                                link  \n",
       "0  https://www.press.et/Ama/?p=39481  \n",
       "1  https://www.press.et/Ama/?p=38334  \n",
       "2  https://www.press.et/Ama/?p=39010  \n",
       "3  https://www.press.et/Ama/?p=39011  \n",
       "4  https://www.press.et/Ama/?p=39012  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_am = pd.read_csv(\"/data/Amharic News Dataset.csv\")\n",
    "\n",
    "df_am.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51483 entries, 0 to 51482\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   headline  51470 non-null  object\n",
      " 1   category  51482 non-null  object\n",
      " 2   date      51483 non-null  object\n",
      " 3   views     51483 non-null  object\n",
      " 4   article   51483 non-null  object\n",
      " 5   link      51483 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_am.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>article</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...</td>\n",
       "      <td>ቢዝነስ</td>\n",
       "      <td>May 9, 2020</td>\n",
       "      <td>433</td>\n",
       "      <td>አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...</td>\n",
       "      <td>https://www.fanabc.com/%e1%8b%a8%e1%8a%a0%e1%8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>«እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር</td>\n",
       "      <td>ሀገር አቀፍ ዜና</td>\n",
       "      <td>May 20, 2020</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ዓለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...</td>\n",
       "      <td>https://amharic.voanews.com//a/5428356.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21252</th>\n",
       "      <td>በሲዳማ ሕዝበ ውሳኔ አሥረኛውን ክልል የሚያስመሠርት ከፍተኛ ድምፅ ተገኘ</td>\n",
       "      <td>ፖለቲካ</td>\n",
       "      <td>24 November 2019</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡዕ ኅዳር 10 ...</td>\n",
       "      <td>https://www.ethiopianreporter.com/article/17395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42924</th>\n",
       "      <td>ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ</td>\n",
       "      <td>ቢዝነስ</td>\n",
       "      <td>October 15, 2018</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...</td>\n",
       "      <td>https://waltainfo.com/am/23599/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46023</th>\n",
       "      <td>121ኛው የአድዋ ድል በዓል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት ዕለ...</td>\n",
       "      <td>ፖለቲካ</td>\n",
       "      <td>February 25, 2017</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>የዘንድሮው 121ኛው የአድዋ ድል በዓል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...</td>\n",
       "      <td>https://waltainfo.com/am/28941/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline    category  \\\n",
       "19808  የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...        ቢዝነስ   \n",
       "37820  «እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር  ሀገር አቀፍ ዜና   \n",
       "21252      በሲዳማ ሕዝበ ውሳኔ አሥረኛውን ክልል የሚያስመሠርት ከፍተኛ ድምፅ ተገኘ        ፖለቲካ   \n",
       "42924                 ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ        ቢዝነስ   \n",
       "46023  121ኛው የአድዋ ድል በዓል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት ዕለ...        ፖለቲካ   \n",
       "\n",
       "                    date    views  \\\n",
       "19808        May 9, 2020      433   \n",
       "37820       May 20, 2020  Unknown   \n",
       "21252   24 November 2019  Unknown   \n",
       "42924   October 15, 2018  Unknown   \n",
       "46023  February 25, 2017  Unknown   \n",
       "\n",
       "                                                 article  \\\n",
       "19808  አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...   \n",
       "37820  ዓለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...   \n",
       "21252  በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡዕ ኅዳር 10 ...   \n",
       "42924  የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...   \n",
       "46023  የዘንድሮው 121ኛው የአድዋ ድል በዓል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...   \n",
       "\n",
       "                                                    link  \n",
       "19808  https://www.fanabc.com/%e1%8b%a8%e1%8a%a0%e1%8...  \n",
       "37820        https://amharic.voanews.com//a/5428356.html  \n",
       "21252    https://www.ethiopianreporter.com/article/17395  \n",
       "42924                    https://waltainfo.com/am/23599/  \n",
       "46023                    https://waltainfo.com/am/28941/  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(df_am)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>article</th>\n",
       "      <th>link</th>\n",
       "      <th>word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...</td>\n",
       "      <td>ቢዝነስ</td>\n",
       "      <td>May 9, 2020</td>\n",
       "      <td>433</td>\n",
       "      <td>አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...</td>\n",
       "      <td>https://www.fanabc.com/%e1%8b%a8%e1%8a%a0%e1%8...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>«እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር</td>\n",
       "      <td>ሀገር አቀፍ ዜና</td>\n",
       "      <td>May 20, 2020</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ዓለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...</td>\n",
       "      <td>https://amharic.voanews.com//a/5428356.html</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21252</th>\n",
       "      <td>በሲዳማ ሕዝበ ውሳኔ አሥረኛውን ክልል የሚያስመሠርት ከፍተኛ ድምፅ ተገኘ</td>\n",
       "      <td>ፖለቲካ</td>\n",
       "      <td>24 November 2019</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡዕ ኅዳር 10 ...</td>\n",
       "      <td>https://www.ethiopianreporter.com/article/17395</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42924</th>\n",
       "      <td>ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ</td>\n",
       "      <td>ቢዝነስ</td>\n",
       "      <td>October 15, 2018</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...</td>\n",
       "      <td>https://waltainfo.com/am/23599/</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46023</th>\n",
       "      <td>121ኛው የአድዋ ድል በዓል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት ዕለ...</td>\n",
       "      <td>ፖለቲካ</td>\n",
       "      <td>February 25, 2017</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>የዘንድሮው 121ኛው የአድዋ ድል በዓል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...</td>\n",
       "      <td>https://waltainfo.com/am/28941/</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline    category  \\\n",
       "19808  የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...        ቢዝነስ   \n",
       "37820  «እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር  ሀገር አቀፍ ዜና   \n",
       "21252      በሲዳማ ሕዝበ ውሳኔ አሥረኛውን ክልል የሚያስመሠርት ከፍተኛ ድምፅ ተገኘ        ፖለቲካ   \n",
       "42924                 ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ        ቢዝነስ   \n",
       "46023  121ኛው የአድዋ ድል በዓል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት ዕለ...        ፖለቲካ   \n",
       "\n",
       "                    date    views  \\\n",
       "19808        May 9, 2020      433   \n",
       "37820       May 20, 2020  Unknown   \n",
       "21252   24 November 2019  Unknown   \n",
       "42924   October 15, 2018  Unknown   \n",
       "46023  February 25, 2017  Unknown   \n",
       "\n",
       "                                                 article  \\\n",
       "19808  አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...   \n",
       "37820  ዓለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...   \n",
       "21252  በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡዕ ኅዳር 10 ...   \n",
       "42924  የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...   \n",
       "46023  የዘንድሮው 121ኛው የአድዋ ድል በዓል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...   \n",
       "\n",
       "                                                    link  word_len  \n",
       "19808  https://www.fanabc.com/%e1%8b%a8%e1%8a%a0%e1%8...        89  \n",
       "37820        https://amharic.voanews.com//a/5428356.html       105  \n",
       "21252    https://www.ethiopianreporter.com/article/17395       271  \n",
       "42924                    https://waltainfo.com/am/23599/       108  \n",
       "46023                    https://waltainfo.com/am/28941/       431  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_len'] = data['article'].str.split().str.len()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51483 entries, 19808 to 14287\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   headline  51470 non-null  object\n",
      " 1   category  51482 non-null  object\n",
      " 2   date      51483 non-null  object\n",
      " 3   views     51483 non-null  object\n",
      " 4   article   51483 non-null  object\n",
      " 5   link      51483 non-null  object\n",
      " 6   word_len  51483 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#method to normalize character level missmatch such as ጸሀይ and ፀሐይ\n",
    "def normalize_char_level_missmatch(input_token):\n",
    "    rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
    "    rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
    "    rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
    "    rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
    "    rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
    "    rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
    "    rep7=re.sub('[ሠ]','ሰ',rep6)\n",
    "    rep8=re.sub('[ሡ]','ሱ',rep7)\n",
    "    rep9=re.sub('[ሢ]','ሲ',rep8)\n",
    "    rep10=re.sub('[ሣ]','ሳ',rep9)\n",
    "    rep11=re.sub('[ሤ]','ሴ',rep10)\n",
    "    rep12=re.sub('[ሥ]','ስ',rep11)\n",
    "    rep13=re.sub('[ሦ]','ሶ',rep12)\n",
    "    rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
    "    rep15=re.sub('[ዑ]','ኡ',rep14)\n",
    "    rep16=re.sub('[ዒ]','ኢ',rep15)\n",
    "    rep17=re.sub('[ዔ]','ኤ',rep16)\n",
    "    rep18=re.sub('[ዕ]','እ',rep17)\n",
    "    rep19=re.sub('[ዖ]','ኦ',rep18)\n",
    "    rep20=re.sub('[ጸ]','ፀ',rep19)\n",
    "    rep21=re.sub('[ጹ]','ፁ',rep20)\n",
    "    rep22=re.sub('[ጺ]','ፂ',rep21)\n",
    "    rep23=re.sub('[ጻ]','ፃ',rep22)\n",
    "    rep24=re.sub('[ጼ]','ፄ',rep23)\n",
    "    rep25=re.sub('[ጽ]','ፅ',rep24)\n",
    "    rep26=re.sub('[ጾ]','ፆ',rep25)\n",
    "    #Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል  \n",
    "    rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
    "    rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
    "    rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
    "    rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
    "    rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
    "    rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
    "    rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
    "    rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
    "    rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
    "    rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
    "    rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
    "    rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
    "    rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
    "    rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
    "    rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
    "    rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
    "    rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
    "    rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
    "    rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
    "    rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
    "    rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
    "    rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ  \n",
    "    return rep48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article'] = data['article'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headline'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['headline'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article'] = data['article'].apply(lambda x: normalize_char_level_missmatch(x))\n",
    "data['headline'] = data['headline'].apply(lambda x: normalize_char_level_missmatch(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...</td>\n",
       "      <td>የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>አለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...</td>\n",
       "      <td>«እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21252</th>\n",
       "      <td>በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡእ ሀዳር 10 ...</td>\n",
       "      <td>በሲዳማ ህዝበ ውሳኔ አስረኛውን ክልል የሚያስመሰርት ከፍተኛ ድምፅ ተገኘ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42924</th>\n",
       "      <td>የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...</td>\n",
       "      <td>ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46023</th>\n",
       "      <td>የዘንድሮው 121ኛው የአድዋ ድል በአል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...</td>\n",
       "      <td>121ኛው የአድዋ ድል በአል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት እለ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "19808  አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...   \n",
       "37820  አለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...   \n",
       "21252  በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡእ ሀዳር 10 ...   \n",
       "42924  የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...   \n",
       "46023  የዘንድሮው 121ኛው የአድዋ ድል በአል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...   \n",
       "\n",
       "                                                headline  \n",
       "19808  የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...  \n",
       "37820  «እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር  \n",
       "21252      በሲዳማ ህዝበ ውሳኔ አስረኛውን ክልል የሚያስመሰርት ከፍተኛ ድምፅ ተገኘ  \n",
       "42924                 ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ  \n",
       "46023  121ኛው የአድዋ ድል በአል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት እለ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = data[['article','headline']]\n",
    "n_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'በአለም ላይ ታላላቅና ዝነኛ የጎዳና ላይ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = normalize_char_level_missmatch(\"በዐለም ላይ ታላላቅና ዝነኛ የጎዳና ላይ\")\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28712/2836481249.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  n_data['is_non_amharic_article'] = n_data['article'].apply(has_non_amharic) # On the text column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 article  \\\n",
      "19808  አዲስ አበባ ፣ ግንቦት 1 ፣ 2012 (ኤፍ.ቢ.ሲ) የአውሮፕላን ነዳጅን ...   \n",
      "37820  አለም አቀፉ የኮሮና ቫይረስ በቢሊየኖች የሚቆጠር ህዝብ ከቤት እንዲውል ም...   \n",
      "21252  በደቡብ ክልል የሲዳማ ዞንን የክልልነት ጥያቄ ለመወሰን ረቡእ ሀዳር 10 ...   \n",
      "42924  የስሎቬኒያ ፕሬዝዳንት ቦሩት ፓሆር በኢትዮጵያ የሚያደርጉተን ይፋዊ ጉብኝት...   \n",
      "46023  የዘንድሮው 121ኛው የአድዋ ድል በአል በአገሪቱ የተቀጣጠለውን የህዳሴ ጉ...   \n",
      "\n",
      "                                                headline  \\\n",
      "19808  የአውሮፕላን ነዳጅን ጨምሮ ሌሎች የነዳጅ ምርቶች ዋጋ ባለበት እንደሚቀጥል...   \n",
      "37820  «እናንብብ እናብብ » ስለ ተሰኘው ሀገራዊ ዘመቻ፤ ቆይታ ከኤልያስ ወንድሙ ጋር   \n",
      "21252      በሲዳማ ህዝበ ውሳኔ አስረኛውን ክልል የሚያስመሰርት ከፍተኛ ድምፅ ተገኘ   \n",
      "42924                 ፕሬዚዳንት ቦሩት ፓሆር  የኢትዮጵያ ጉብኝታቸውን ጀመሩ   \n",
      "46023  121ኛው የአድዋ ድል በአል ህዳሲያችንን ለማረጋገጥ ቃል የሚንገባበት እለ...   \n",
      "\n",
      "       is_non_amharic_article  is_non_amharic_headline  \n",
      "19808                   False                    False  \n",
      "37820                   False                    False  \n",
      "21252                   False                    False  \n",
      "42924                   False                    False  \n",
      "46023                   False                    False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28712/2836481249.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  n_data['is_non_amharic_headline'] = n_data['headline'].apply(has_non_amharic) # On the summary column\n"
     ]
    }
   ],
   "source": [
    "# Checking for any gibberish, non-Amharic or unexpected characters\n",
    "\n",
    "# Pattern for Geez (Amharic) characters, numbers, spaces, and specific punctuations\n",
    "geez_pattern = re.compile(r'[\\u1200-\\u137F0-9\\s‹›፡።፣፤፦]')\n",
    "\n",
    "def has_non_amharic(text):\n",
    "  '''\n",
    "  Determine if the given text contains significant non-Amharic characters (50% or more).\n",
    "\n",
    "  Args:\n",
    "    text (str): The text to be analyzed.\n",
    "\n",
    "  Returns:\n",
    "    bool: True if non-Amharic content is significant, False otherwise.\n",
    "  '''\n",
    "  # Checking if the text is a string\n",
    "  if not isinstance(text, str):\n",
    "      return False\n",
    "\n",
    "  # Finding the regex pattern for Amharic\n",
    "  amharic_chars = geez_pattern.findall(text)\n",
    "\n",
    "  # 80% threshold to say Amharic or non-Amharic (i.e., at least 80% of the characters have to be Amharic)\n",
    "  # This percentage was set to 50% during the preparation of Amharic-1\n",
    "  if len(amharic_chars) / len(text) < 0.8:\n",
    "    return True\n",
    "\n",
    "  return False\n",
    "\n",
    "# Applying non-Amharic check\n",
    "n_data['is_non_amharic_article'] = n_data['article'].apply(has_non_amharic) # On the text column\n",
    "n_data['is_non_amharic_headline'] = n_data['headline'].apply(has_non_amharic) # On the summary column\n",
    "\n",
    "# Filtering out non-Amharic rows\n",
    "filtered_data = n_data[~(n_data['is_non_amharic_article'] | n_data['is_non_amharic_headline'])]\n",
    "\n",
    "print(filtered_data.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahbubah/Desktop/week-6/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Looking at the number of tokens\n",
    "# Using mT5's tokenizer to find the number of tokens\n",
    "from transformers import MT5Tokenizer\n",
    "tokenizer = MT5Tokenizer.from_pretrained('google/mt5-small')\n",
    "\n",
    "def count_tokens(text, tokenizer):\n",
    "    '''\n",
    "    Count the number of tokens in a given text using a specified tokenizer.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be tokenized.\n",
    "        tokenizer: The tokenizer to be used for tokenizing the text.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of tokens in the tokenized text.\n",
    "    '''\n",
    "\n",
    "    # Encoding the text using the tokenizer\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "    # Returning the number of tokens\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28712/270046965.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_length'] = filtered_data['article'].apply(len)\n",
      "/tmp/ipykernel_28712/270046965.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_length'] = filtered_data['headline'].apply(len)\n",
      "/tmp/ipykernel_28712/270046965.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_word_count'] = filtered_data['article'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_28712/270046965.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_word_count'] = filtered_data['headline'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_28712/270046965.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_token_count'] = filtered_data['article'].apply(lambda x: count_tokens(x, tokenizer))\n",
      "/tmp/ipykernel_28712/270046965.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_token_count'] = filtered_data['headline'].apply(lambda x: count_tokens(x, tokenizer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       article_length  headline_length  article_word_count  \\\n",
      "count    50684.000000     50684.000000        50684.000000   \n",
      "mean      1340.279536        45.967209          248.758385   \n",
      "std       1285.543358        18.780061          241.694061   \n",
      "min          1.000000         2.000000            0.000000   \n",
      "25%        552.000000        34.000000          102.000000   \n",
      "50%        979.000000        44.000000          179.000000   \n",
      "75%       1698.000000        56.000000          314.000000   \n",
      "max      36216.000000      1421.000000         6738.000000   \n",
      "\n",
      "       headline_word_count  article_token_count  headline_token_count  \n",
      "count         50684.000000         50684.000000          50684.000000  \n",
      "mean              9.239681           860.451148             31.920961  \n",
      "std               3.629047           818.879162             12.228569  \n",
      "min               0.000000             1.000000              1.000000  \n",
      "25%               7.000000           360.000000             24.000000  \n",
      "50%               9.000000           629.000000             31.000000  \n",
      "75%              11.000000          1088.000000             38.000000  \n",
      "max             281.000000         22320.000000            902.000000  \n",
      "Most common words:  [('ላይ', 141073), ('እና', 96376), ('ወደ', 68746), ('ጋር', 58711), ('ውስጥ', 51185), ('አቶ', 47724), ('ነው', 45336), ('ከተማ', 33317), ('መሆኑን', 33098), ('ቤት', 32735)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Statistical analysis of the dataset\n",
    "filtered_data['article_length'] = filtered_data['article'].apply(len)\n",
    "filtered_data['headline_length'] = filtered_data['headline'].apply(len)\n",
    "\n",
    "# Word counts\n",
    "filtered_data['article_word_count'] = filtered_data['article'].apply(lambda x: len(x.split()))\n",
    "filtered_data['headline_word_count'] = filtered_data['headline'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Token counts\n",
    "filtered_data['article_token_count'] = filtered_data['article'].apply(lambda x: count_tokens(x, tokenizer))\n",
    "filtered_data['headline_token_count'] = filtered_data['headline'].apply(lambda x: count_tokens(x, tokenizer))\n",
    "\n",
    "# Descriptive statistics\n",
    "print(filtered_data[['article_length', 'headline_length', 'article_word_count', 'headline_word_count', 'article_token_count', 'headline_token_count']].describe())\n",
    "\n",
    "# Counting most common words\n",
    "all_words = ' '.join(filtered_data['article']).split()\n",
    "word_counts = Counter(all_words)\n",
    "print(\"Most common words: \", word_counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28712/77299415.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article'] = filtered_data['article'].apply(\n",
      "/tmp/ipykernel_28712/77299415.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline'] = filtered_data['headline'].apply(\n",
      "/tmp/ipykernel_28712/77299415.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_length'] = filtered_data['article'].apply(len)\n",
      "/tmp/ipykernel_28712/77299415.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_length'] = filtered_data['headline'].apply(len)\n",
      "/tmp/ipykernel_28712/77299415.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_word_count'] = filtered_data['article'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_28712/77299415.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_word_count'] = filtered_data['headline'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_28712/77299415.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['article_token_count'] = filtered_data['article'].apply(lambda x: count_tokens(x, tokenizer))\n",
      "/tmp/ipykernel_28712/77299415.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['headline_token_count'] = filtered_data['headline'].apply(lambda x: count_tokens(x, tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_token_count</th>\n",
       "      <th>headline_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50684.000000</td>\n",
       "      <td>50684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>844.688541</td>\n",
       "      <td>31.494633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>801.854609</td>\n",
       "      <td>12.041356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>354.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1070.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21493.000000</td>\n",
       "      <td>880.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_token_count  headline_token_count\n",
       "count         50684.000000          50684.000000\n",
       "mean            844.688541             31.494633\n",
       "std             801.854609             12.041356\n",
       "min               1.000000              1.000000\n",
       "25%             354.000000             24.000000\n",
       "50%             617.000000             30.000000\n",
       "75%            1070.000000             38.000000\n",
       "max           21493.000000            880.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc_and_special_chars(text):\n",
    "  '''\n",
    "    Remove punctuation and special characters from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to remove punctuation and special characters.\n",
    "\n",
    "    Returns:\n",
    "        str: The text stripped of punctuation and special characters.\n",
    "  '''\n",
    "\n",
    "  normalized_text = re.sub('[\\!\\@\\#$\\%\\^\\«\\»\\&\\*\\…\\{\\}\\;\\“\\”\\›\\’\\‘\\\"\\'\\:\\,\\.\\‹\\/\\<\\>\\?\\\\|\\`\\´\\~\\-\\=\\+\\፡\\፤\\;\\፦\\፥\\፧\\፨\\፠\\፣]', '',text)\n",
    "  return normalized_text\n",
    "\n",
    "# Remove all ascii characters\n",
    "def remove_ascii_and_numbers(text_input):\n",
    "  '''\n",
    "    Remove ASCII characters and numbers from the given text.\n",
    "\n",
    "    Args:\n",
    "        text_input (str): The text from which to remove ASCII characters and numbers.\n",
    "\n",
    "    Returns:\n",
    "        str: The text without any ASCII characters and numbers.\n",
    "  '''\n",
    "\n",
    "  return re.sub('[A-Za-z]','',text_input)\n",
    "     \n",
    "\n",
    "# Normalizing the article and headline columns using the three normalization functions\n",
    "filtered_data['article'] = filtered_data['article'].apply(\n",
    "    lambda x: remove_ascii_and_numbers(\n",
    "        remove_punc_and_special_chars(\n",
    "            normalize_char_level_missmatch(x))))\n",
    "\n",
    "filtered_data['headline'] = filtered_data['headline'].apply(\n",
    "    lambda x: remove_ascii_and_numbers(\n",
    "        remove_punc_and_special_chars(\n",
    "            normalize_char_level_missmatch(x))))\n",
    "\n",
    "# Updating the statistical columns following the normalization steps\n",
    "# Length of the article and headline\n",
    "filtered_data['article_length'] = filtered_data['article'].apply(len)\n",
    "filtered_data['headline_length'] = filtered_data['headline'].apply(len)\n",
    "\n",
    "# Word count in the article and headline\n",
    "filtered_data['article_word_count'] = filtered_data['article'].apply(lambda x: len(x.split()))\n",
    "filtered_data['headline_word_count'] = filtered_data['headline'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Token count in the article and headline\n",
    "filtered_data['article_token_count'] = filtered_data['article'].apply(lambda x: count_tokens(x, tokenizer))\n",
    "filtered_data['headline_token_count'] = filtered_data['headline'].apply(lambda x: count_tokens(x, tokenizer))\n",
    "\n",
    "# Showing descriptive statistics of the token counts\n",
    "filtered_data[['article_token_count', 'headline_token_count']].describe()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tokens)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Concatenate all articles into a single string\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mfiltered_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Display the tokens\u001b[39;00m\n\u001b[1;32m     25\u001b[0m display_tokens(text, tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_data' is not defined"
     ]
    }
   ],
   "source": [
    "def display_tokens(text, tokenizer):\n",
    "    '''\n",
    "    Display the tokens of a given text using a specified tokenizer.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be tokenized and displayed.\n",
    "        tokenizer: The tokenizer to be used for tokenizing the text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Print the tokens\n",
    "    print(\"Tokens:\")\n",
    "    print(tokens)\n",
    "\n",
    "\n",
    "# Concatenate all articles into a single string\n",
    "text = ' '.join(filtered_data['article'])\n",
    "\n",
    "# Display the tokens\n",
    "display_tokens(text, tokenizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
